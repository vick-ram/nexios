from abc import ABC, abstractmethod
from datetime import date, datetime, time, timedelta
from decimal import Decimal
from enum import Enum, StrEnum
import inspect
from ipaddress import IPv4Address, IPv4Network, IPv6Address, IPv6Network
from pathlib import Path
from typing import (
    Annotated,
    Any,
    Dict,
    List,
    Optional,
    Tuple,
    Type,
    Union,
    get_args,
    get_origin,
)
from urllib.parse import urlparse
from uuid import UUID

from pydantic import EmailStr
from nexios.orm.model import BaseModel, ColumnInfo


class PostgreSQLDriver(StrEnum):
    ASYNCPG = "asyncpg"
    PG8000 = "pg8000"
    PSYCOPG3 = "psycopg3"


class MySQLDriver(StrEnum):
    MYSQL_CONNECTOR = "mysql-connector"
    PYMySQL = "pymysql"
    AIOMYSQL = "aiomysql"


class SQLiteDriver(StrEnum):
    AIOSQLITE = "aiosqlite"
    SQLITE3 = "sqlite3"


class Dialect(ABC):
    """Base class for database dialects"""

    @abstractmethod
    def get_type_mapping(
        self,
        max_digits: Optional[int] = None,
        precision: Optional[int] = None,
        scale: Optional[int] = None,
    ) -> Dict[type, str]: ...

    @abstractmethod
    def auto_increment_keyword(self) -> str: ...

    @abstractmethod
    def quote_identifier(self, identifier: str) -> str: ...


class SQLiteDialect(Dialect):
    def get_type_mapping(
        self,
        max_digits: Optional[int] = None,
        precision: Optional[int] = None,
        scale: Optional[int] = None,
    ) -> Dict[type, str]:
        return {
            int: "INTEGER",
            str: "TEXT",
            float: "REAL",
            bool: "INTEGER",
            bytes: "BLOB",
            datetime: "TEXT",
            date: "TEXT",
            time: "TEXT",
            timedelta: "INTEGER",
            Decimal: "NUMERIC",
            UUID: "TEXT",
            dict: "TEXT",
            list: "TEXT",
            Enum: "TEXT",
            object: "BLOB",
        }

    def auto_increment_keyword(self) -> str:
        return "AUTOINCREMENT"

    def quote_identifier(self, identifier: str) -> str:
        return f'"{identifier}"'


class PostgreSQLDialect(Dialect):
    def get_type_mapping(
        self,
        max_digits: Optional[int] = None,
        precision: Optional[int] = None,
        scale: Optional[int] = None,
    ) -> Dict[type, str]:
        string_type = (
            f"VARCHAR({max_digits})" if max_digits and max_digits <= 255 else "TEXT"
        )
        return {
            int: "BIGINT",
            str: string_type,
            Path: "TEXT",
            float: "DOUBLE PRECISION",
            bool: "BOOLEAN",
            bytes: "BYTEA",
            datetime: "TIMESTAMP",
            date: "DATE",
            time: "TIME",
            timedelta: "INTERVAL",
            Decimal: f"NUMERIC({precision}, {scale})",
            UUID: "UUID",
            IPv4Address: "INET",
            IPv6Address: "INET",
            IPv4Network: "INET",
            IPv6Network: "INET",
            dict: "JSONB",
            list: "JSONB",
            Enum: "TEXT",
            object: "BYTEA",
        }

    def auto_increment_keyword(self) -> str:
        return "GENERATED BY DEFAULT AS IDENTITY"

    def quote_identifier(self, identifier: str) -> str:
        return f'"{identifier}"'


class MySQLDialect(Dialect):
    def get_type_mapping(
        self,
        max_digits: Optional[int] = None,
        precision: Optional[int] = None,
        scale: Optional[int] = None,
    ) -> Dict[type, str]:
        def resolve_str() -> str:
            if max_digits:
                if max_digits <= 255:
                    return f"VARCHAR({max_digits})"
                elif max_digits <= 65535:
                    return "TEXT"
                elif max_digits <= 16777215:
                    return "MEDIUMTEXT"
                else:
                    return "LONGTEXT"
            else:
                return "'TEXT"
        string_type = resolve_str()
        
        return {
            int: "BIGINT",
            str: string_type,
            float: "DOUBLE",
            bool: "BOOLEAN",
            bytes: "BLOB",
            datetime: "DATETIME",
            date: "DATE",
            time: "TIME",
            timedelta: "BIGINT",
            Decimal: f"DECIMAL({precision}, {scale})",
            UUID: "CHAR(36)",
            IPv4Address: "VARCHAR(45)",
            IPv6Address: "VARCHAR(45)",
            IPv4Network: "VARCHAR(45)",
            IPv6Network: "VARCHAR(45)",
            dict: "JSON",
            list: "JSON",
            Enum: "VARCHAR(255)",
            object: "BLOB",
        }

    def auto_increment_keyword(self) -> str:
        return "AUTO_INCREMENT"

    def quote_identifier(self, identifier: str) -> str:
        return f"`{identifier}`"


class DDLGenerator:
    """Generate DDL statements from ORM model"""

    def __init__(self, dialect: Dialect) -> None:
        self.dialect = dialect or SQLiteDialect()

    def create_table(self, model_class: Type[BaseModel]) -> str:
        """Generate CREATE TABLE statements"""
        table_name = model_class.__orm_config__.table_name
        columns = self._get_column_definitions(model_class)
        constraints = self._get_table_constraints(model_class)

        column_defs = ",\n    ".join(columns + constraints)

        return f"CREATE TABLE IF NOT EXISTS {self.dialect.quote_identifier(table_name)} (\n    {column_defs}\n);"  # type: ignore

    def delete(self, model_class: Type[BaseModel]) -> str:
        """Delete statement
        model_class: Instance of the BaseModel
        name: is any field value that matches the condition
        """
        from nexios.orm.query import ColumnExpression

        tablename = model_class.__orm_config__.table_name
        assert tablename is not None
        assert model_class.__orm_config__.primary_key is not None
        condition = ColumnExpression(
            model_class, model_class.__orm_config__.primary_key
        )
        sql = (
            f"DELETE FROM {self.dialect.quote_identifier(tablename)} WHERE {condition}"
        )

        return sql

    def upsert(self, model_class: Type[BaseModel]) -> Tuple[str, tuple]:
        """Insert or update statement"""
        insert_sql, params = self._insert(model_class)
        sql = insert_sql + " " + self._update(model_class)
        return sql, params

    def drop_table(self, model_class: Type[BaseModel]) -> str:
        """Generate DROP TABLE statement"""
        table_name = model_class.__orm_config__.table_name
        return f"DROP TABLE IF EXISTS {self.dialect.quote_identifier(table_name)};"  # type: ignore

    def create_indexes(self, model_class: Type[BaseModel]) -> List[str]:
        """Generate CREATE INDEX statements"""
        indexes = []
        table_name = model_class.__orm_config__.table_name

        for field_name, column_info in model_class.get_fields().items():
            if column_info.index and not column_info.unique:
                index_name = f"idx_{table_name}_{field_name}"
                indexes.append(
                    f"CREATE INDEX {self.dialect.quote_identifier(index_name)} "
                    f"ON {self.dialect.quote_identifier(table_name)} "  # type: ignore
                    f"({self.dialect.quote_identifier(field_name)})"
                )

        for i, index_def in enumerate(model_class.__orm_config__.indexes):
            columns = ", ".join(
                self.dialect.quote_identifier(col) for col in index_def["columns"]
            )
            index_name = index_def.get("name", f"idx_{table_name}_{i}")
            unique = "UNIQUE " if index_def.get("unique", False) else ""
            indexes.append(
                f"CREATE {unique}INDEX {self.dialect.quote_identifier(index_name)} "
                f"ON {self.dialect.quote_identifier(table_name)} ({columns});"  # type: ignore
            )

        return indexes

    def _get_param_placeholder(self) -> str:
        placeholder = ""

        if isinstance(self.dialect, PostgreSQLDialect):
            placeholder = "%s"
        elif isinstance(self.dialect, MySQLDialect):
            placeholder = "%s"
        else:
            placeholder = "?"

        return placeholder

    def _insert(self, model_class: Type[BaseModel]) -> Tuple[str, tuple]:
        fields_to_save: Dict[str, Any] = {}
        tablename = model_class.__orm_config__.table_name
        placeholder = self._get_param_placeholder()
        fields = model_class.get_fields()

        for field_name, field_info in fields.items():
            value = getattr(model_class, field_name, None)
            if value is not None:
                fields_to_save[field_name] = value

        field_names = list(fields_to_save.keys())
        placeholders = ", ".join(len(field_names) * [placeholder])
        field_names_str = ", ".join(field_names)
        assert tablename is not None
        sql = f"INSERT INTO {self.dialect.quote_identifier(tablename)} ({field_names_str}) VALUES ({placeholders});"
        params = tuple(getattr(model_class, fname) for fname in field_names)

        return sql, params

    def _update(self, model_class: Type[BaseModel]):
        # To be fixed: not a complete implementation
        fields = model_class.get_fields()
        update_sql = ""
        fields_to_update = []

        for field_name, field_info in fields.items():
            if not field_info.primary_key:
                fields_to_update.append(field_name)

        for field in fields_to_update:
            if isinstance(self.dialect, PostgreSQLDialect):
                update_sql = f"ON CONFLICT ({model_class.__orm_config__.primary_key}) DO UPDATE SET {field}"
            elif isinstance(self.dialect, MySQLDialect):
                update_sql = f"ON DUPLICATE KEY UPDATE {field} = VALUES({field})"
            else:
                update_sql = f"ON CONFLICT ({model_class.__orm_config__.primary_key}) DO UPDATE SET {field} = excluded.{field}"
        return update_sql

    def _get_column_definitions(self, model_class: Type[BaseModel]) -> List[str]:
        """Generate column definitions for CREATE TABLE"""
        columns = []
        fields = model_class.get_fields()

        for field_name, column_info in fields.items():
            column_def = self._build_column_definition(
                field_name, column_info, model_class
            )
            columns.append(column_def)

        return columns

    def _build_column_definition(
        self, field_name: str, column_info: ColumnInfo, model_class: Type[BaseModel]
    ) -> str:
        """Build a single column definition"""
        parts = [self.dialect.quote_identifier(field_name)]

        field_type = self._get_field_type(model_class, field_name)
        db_type = column_info.db_type or self._map_python_type(field_type)

        parts.append(db_type)

        if column_info.primary_key:
            parts.append("PRIMARY KEY")
            if column_info.auto_increment:
                if db_type.upper() in (
                    "INTEGER",
                    "INT",
                    "BIGINT",
                    "SMALLINT",
                    "SERIAL",
                    "BIGSERIAL",
                ):
                    parts.append(self.dialect.auto_increment_keyword())
        elif not column_info.nullable:
            parts.append("NOT NULL")

        if column_info.unique and not column_info.primary_key:
            parts.append("UNIQUE")

        default_value = self._get_default_value(model_class, field_name)
        if default_value is not None:
            parts.append(f"DEFAULT {default_value}")

        return " ".join(parts)

    def _get_field_type(self, model_class: Type[BaseModel], field_name: str) -> type:
        """Get the python type for a field"""
        annotation = model_class.__annotations__.get(field_name, str)

        while True:
            origin = get_origin(annotation)

            # Annotated[T, ...]
            if origin is Annotated:
                annotation = get_args(annotation)[0]
                continue

            # Optional / Union[T, None]
            if origin is Union:
                args = [arg for arg in get_args(annotation) if arg is not type(None)]
                annotation = args[0] if args else str
                continue

            break

        return annotation

    def _map_python_type(self, python_type: type) -> str:
        """Map python type to database type"""
        type_mapping = self.dialect.get_type_mapping()

        if python_type in type_mapping:
            return type_mapping[python_type]

        # Enum subclasses
        if inspect.isclass(python_type) and issubclass(python_type, Enum):
            return type_mapping[Enum]

        return type_mapping.get(object, "TEXT")

    def _get_default_value(
        self, model_class: Type[BaseModel], field_name: str
    ) -> Optional[str]:
        """Get SQL default value for a field"""
        # field = model_class.__orm_config__.fields.get(field_name)
        field = model_class.get_fields().get(field_name)

        if not field:
            return None

        default = field.default

        if default is None:
            return None

        if callable(default):
            return None

        if isinstance(default, str):
            return f"'{default}'"

        if isinstance(default, Enum):
            return f"'{default.value}'"

        if isinstance(default, bool):
            return "TRUE" if default else "FALSE"

        if isinstance(default, (dict, list)):
            import json

            return f"'{json.dumps(default)}'"

        if isinstance(default, (int, float, Decimal)):
            return str(default)

        if isinstance(default, UUID):
            return f"'{default}'"

        if isinstance(default, (datetime, date, time)):
            return f"'{default.isoformat()}'"
        return f"'{str(default)}'"

    def _get_table_constraints(self, model_class: Type[BaseModel]) -> List[str]:
        """Generate table-level constraints"""
        constraints = []

        for i, unique_cols in enumerate(model_class.__orm_config__.unique_constraints):
            columns = ", ".join(
                self.dialect.quote_identifier(col) for col in unique_cols
            )
            constraints.append(
                f"CONSTRAINT uk_{model_class.__orm_config__.table_name}_{i} UNIQUE ({columns})"
            )
        constraints.extend(self._get_foreign_key_constraints(model_class))
        return constraints

    def _get_foreign_key_constraints(self, model_class: Type[BaseModel]) -> List[str]:
        """Generate FOREIGN KEY constraints"""
        constraints = []
        fields = model_class.get_fields()

        for field_name, column_info in fields.items():
            if column_info.foreign_key:
                fk_parts = column_info.foreign_key.split(".")
                ref_table = fk_parts[0]
                ref_column = fk_parts[1] if len(fk_parts) > 1 else "id"

                constraint_name = (
                    f"fk_{model_class.__orm_config__.table_name}_{field_name}"
                )
                constraints.append(
                    f"CONSTRAINT {constraint_name} "
                    f"FOREIGN KEY ({self.dialect.quote_identifier(field_name)}) "
                    f"REFERENCES {self.dialect.quote_identifier(ref_table)} ({self.dialect.quote_identifier(ref_column)})"
                )
        return constraints


class DatabaseDetector:
    """Automatically detects database type and driver from connection parameters."""

    @staticmethod
    def detect_from_url(
        url: str, is_async: bool = False
    ) -> Tuple[Dialect, str, Dict[str, Any]]:
        """Detect database type from connection URL."""
        parsed = urlparse(url)
        scheme = parsed.scheme.lower()

        def parse_query(q: str) -> Dict[str, Any]:
            from urllib.parse import parse_qs

            values = {}
            for k, v in parse_qs(q).items():
                item = v[0] if len(v) == 1 else v
                if isinstance(item, str):
                    if item.isdigit():
                        item = int(item)
                    elif item.replace(".", "").isdigit() and item.count(".") == 1:
                        item = float(item)
                    elif item.lower() in ("true", "false"):
                        item = item.lower() == "true"
                    elif item.lower() in ("none", "null"):
                        item = None
                values[k] = item
            return values

        scheme = scheme.split("+")[-1]

        if scheme == "sqlite":
            db_type = SQLiteDialect()
            driver = DatabaseDetector._detect_sqlite_driver(is_async)
            database_path = parsed.path.lstrip("/") or ":memory:"
            kwargs = {"database": database_path}

        elif scheme in ["postgres", "postgresql"]:
            db_type = PostgreSQLDialect()
            driver = DatabaseDetector._detect_postgres_driver(is_async)
            kwargs = {
                "host": parsed.hostname or "localhost",
                "port": parsed.port or 5432,
                "dbname": parsed.path.lstrip("/"),
                "user": parsed.username,
                "password": parsed.password,
            }

        elif scheme in ["mysql", "mariadb"]:
            db_type = MySQLDialect()
            driver = DatabaseDetector._detect_mysql_driver(is_async)
            kwargs = {
                "host": parsed.hostname or "localhost",
                "port": parsed.port or 3306,
                "database": parsed.path.lstrip("/"),
                "user": parsed.username,
                "password": parsed.password,
            }

        else:
            raise ValueError(f"Unsupported database URL scheme: {scheme}")

        if parsed.query:
            kwargs.update(parse_query(parsed.query))

        clean_kwargs = {k: v for k, v in kwargs.items() if v is not None}

        return db_type, driver, clean_kwargs

    @staticmethod
    def detect_from_kwargs(
        kwargs: Dict[str, Any], is_async: bool = False
    ) -> Tuple[Dialect, str]:
        """Detect database type from connection kwargs."""
        if "driver" in kwargs:
            driver = kwargs["driver"]
            if driver in [d.value for d in PostgreSQLDriver]:
                return PostgreSQLDialect(), driver
            elif driver in [d.value for d in MySQLDriver]:
                return MySQLDialect(), driver
            elif driver in [d.value for d in SQLiteDriver]:
                return SQLiteDialect(), driver
            else:
                raise ValueError(f"Unsupported driver: {driver}")

        if "dialect" in kwargs:
            dialect = kwargs["dialect"]
            if isinstance(dialect, Dialect):
                if isinstance(dialect, SQLiteDialect):
                    return dialect, DatabaseDetector._detect_sqlite_driver(is_async)
                elif isinstance(dialect, PostgreSQLDialect):
                    return dialect, DatabaseDetector._detect_postgres_driver(is_async)
                elif isinstance(dialect, MySQLDialect):
                    return dialect, DatabaseDetector._detect_mysql_driver(is_async)
            if isinstance(dialect, str):
                d = dialect.lower()
                if d in ("sqlite", "sqlite3"):
                    return SQLiteDialect(), DatabaseDetector._detect_sqlite_driver(
                        is_async
                    )
                if d in ("postgres", "postgresql"):
                    return (
                        PostgreSQLDialect(),
                        DatabaseDetector._detect_postgres_driver(is_async),
                    )
                if d in ("mysql", "mariadb"):
                    return MySQLDialect(), DatabaseDetector._detect_mysql_driver(
                        is_async
                    )
            raise ValueError(f"Unsupported dialect: {dialect}")

        database_value = kwargs.get("database", "")
        if isinstance(database_value, str):
            if (
                database_value == ":memory:"
                or database_value.startswith("file:")
                or database_value.endswith(".db")
                or database_value.endswith(".sqlite")
                or database_value.endswith("sqlite3")
            ):
                driver = DatabaseDetector._detect_sqlite_driver(is_async)
                return SQLiteDialect(), driver
        pg_indicators = [
            kwargs.get("port") == 5432,
            "postgres" in str(kwargs.get("dsn", "")),
            "postgres" in str(kwargs.get("host", "")),
            "postgres" in str(kwargs.get("dbname", "")),
            any(key in kwargs for key in ["sslmode", "application_name"]),
        ]

        if any(pg_indicators):
            driver = DatabaseDetector._detect_postgres_driver(is_async)
            return PostgreSQLDialect(), driver

        mysql_indicators = [
            kwargs.get("port") == 3306,
            any(key in kwargs for key in ["unix_socket", "auth_plugin", "charset"]),
            "mysql" in str(kwargs.get("host", "")),
            "mysql" in str(kwargs.get("database", "")),
        ]

        if any(mysql_indicators):
            driver = DatabaseDetector._detect_mysql_driver(is_async)
            return MySQLDialect(), driver

        if "database" in kwargs and isinstance(kwargs["database"], str):
            if not any(key in kwargs for key in ["host", "port", "user", "password"]):
                driver = DatabaseDetector._detect_sqlite_driver(is_async)
                return SQLiteDialect(), driver

        try:
            DatabaseDetector._detect_postgres_driver(is_async)
            return PostgreSQLDialect(), DatabaseDetector._detect_postgres_driver(
                is_async
            )
        except ImportError:
            pass

        try:
            DatabaseDetector._detect_mysql_driver(is_async)
            return MySQLDialect(), DatabaseDetector._detect_mysql_driver(is_async)
        except ImportError:
            pass

        # Ultimate fallback to SQLite
        driver = DatabaseDetector._detect_sqlite_driver(is_async)
        return SQLiteDialect(), driver

    @staticmethod
    def _detect_sqlite_driver(is_async: bool = False):
        """Detect which SQLite driver is available."""
        if is_async:
            try:
                import aiosqlite  # noqa

                return SQLiteDriver.AIOSQLITE
            except ImportError:
                raise ImportError("aiosqlite is required for async SQLite operations")
        else:
            try:
                import sqlite3  # noqa

                return SQLiteDriver.SQLITE3
            except ImportError:
                raise ImportError("sqlite3 is required for sync SQLite operations")

    @staticmethod
    def _detect_postgres_driver(is_async: bool = False):
        """Detect which PostgreSQL driver is available."""
        if is_async:
            try:
                import asyncpg  # noqa

                return PostgreSQLDriver.ASYNCPG
            except ImportError:
                try:
                    import psycopg  # noqa

                    return PostgreSQLDriver.PSYCOPG3
                except ImportError:
                    raise ImportError(
                        "No async PostgreSQL driver found. Please install one of: "
                        "psycopg3 or asyncpg"
                    )
        else:
            try:
                import psycopg  # noqa

                return PostgreSQLDriver.PSYCOPG3
            except ImportError:
                try:
                    import pg8000  # noqa

                    return PostgreSQLDriver.PG8000
                except ImportError:
                    raise ImportError(
                        "No PostgreSQL driver found. Please install one of: "
                        "psycopg3, or pg8000"
                    )

    @staticmethod
    def _detect_mysql_driver(is_async: bool = False):
        """Detect which MySQL driver is available."""
        if is_async:
            try:
                import aiomysql  # noqa

                return MySQLDriver.AIOMYSQL
            except ImportError:
                raise ImportError("aiomysql is required for async MySQL operations")
        else:
            try:
                import mysql.connector  # noqa

                return MySQLDriver.MYSQL_CONNECTOR
            except ImportError:
                try:
                    import pymysql  # noqa

                    return MySQLDriver.PYMySQL
                except ImportError:
                    raise ImportError(
                        "No MySQL driver found. Please install one of: "
                        "mysql-connector-python or pymysql"
                    )
